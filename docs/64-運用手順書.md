# workflow.tsåˆ†å‰² é‹ç”¨æ‰‹é †æ›¸

## ğŸ“‹ é‹ç”¨æ‰‹é †æ›¸æ¦‚è¦

**ä½œæˆæ—¥**: 2025-09-28
**å¯¾è±¡**: workflow.ts ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å‹åˆ†å‰²å¾Œã®é‹ç”¨
**é©ç”¨ç¯„å›²**: é–‹ç™ºãƒ»ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ãƒ»æœ¬ç•ªç’°å¢ƒ
**é‹ç”¨æ–¹é‡**: DevOpsãƒ»è‡ªå‹•åŒ–ãƒ»äºˆé˜²ä¿å…¨

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

### 1. é–‹ç™ºç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤

#### å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
```bash
#!/bin/bash
# scripts/pre-deploy-check.sh

echo "ğŸ” ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯é–‹å§‹"

# Node.js ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
node_version=$(node --version)
if [[ ! "$node_version" =~ ^v18 ]]; then
  echo "âŒ Node.js v18ãŒå¿…è¦ã§ã™ (ç¾åœ¨: $node_version)"
  exit 1
fi

# ä¾å­˜é–¢ä¿‚ç¢ºèª
npm list --depth=0 > /dev/null
if [ $? -ne 0 ]; then
  echo "âŒ ä¾å­˜é–¢ä¿‚ã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
  exit 1
fi

# TypeScriptå‹ãƒã‚§ãƒƒã‚¯
npm run type-check
if [ $? -ne 0 ]; then
  echo "âŒ TypeScriptå‹ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™"
  exit 1
fi

# å˜ä½“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
npm test
if [ $? -ne 0 ]; then
  echo "âŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¦ã„ã¾ã™"
  exit 1
fi

echo "âœ… ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯å®Œäº†"
```

#### ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å€‹åˆ¥ãƒ‡ãƒ—ãƒ­ã‚¤
```bash
#!/bin/bash
# scripts/deploy-microservices.sh

services=(
  "workflow-types:8001"
  "workflow-requests:8002"
  "workflow-dashboard:8003"
  "emergency-approval:8004"
  "delegation-approval:8005"
  "proxy-approval:8006"
  "parallel-approval:8007"
  "sequential-approval:8008"
  "auto-approval:8009"
)

echo "ğŸš€ ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹"

for service_info in "${services[@]}"; do
  IFS=':' read -r service port <<< "$service_info"

  echo "ğŸ“¦ $service ã‚’ãƒãƒ¼ãƒˆ $port ã«ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­..."

  # ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
  pm2 stop "workflow-$service" 2>/dev/null || true

  # æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
  pm2 start "dist/routes/workflow/$service.js" \
    --name "workflow-$service" \
    --env PORT=$port \
    --env NODE_ENV=development

  # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
  sleep 5
  health_check $port

  if [ $? -eq 0 ]; then
    echo "âœ… $service ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸ"
  else
    echo "âŒ $service ãƒ‡ãƒ—ãƒ­ã‚¤å¤±æ•—"
    exit 1
  fi
done

echo "ğŸ‰ å…¨ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†"
```

#### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–¢æ•°
```bash
#!/bin/bash
# scripts/health-check.sh

health_check() {
  local port=$1
  local max_attempts=10
  local attempt=1

  while [ $attempt -le $max_attempts ]; do
    echo "ğŸ” ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è©¦è¡Œ $attempt/$max_attempts (ãƒãƒ¼ãƒˆ: $port)"

    response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:$port/health)

    if [ "$response" = "200" ]; then
      echo "âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ (ãƒãƒ¼ãƒˆ: $port)"
      return 0
    fi

    echo "â³ å¾…æ©Ÿä¸­... (5ç§’)"
    sleep 5
    ((attempt++))
  done

  echo "âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•— (ãƒãƒ¼ãƒˆ: $port)"
  return 1
}
```

### 2. ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤

#### Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè£…
```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

BLUE_PORT=8000
GREEN_PORT=8100
CURRENT_ENV=$(get_current_environment)

echo "ğŸ”„ Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹ (ç¾åœ¨: $CURRENT_ENV)"

if [ "$CURRENT_ENV" = "blue" ]; then
  TARGET_ENV="green"
  TARGET_PORT=$GREEN_PORT
else
  TARGET_ENV="blue"
  TARGET_PORT=$BLUE_PORT
fi

echo "ğŸ“¦ $TARGET_ENV ç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­..."

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤
deploy_to_environment $TARGET_ENV $TARGET_PORT

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ»ç…™ãƒ†ã‚¹ãƒˆ
run_smoke_tests $TARGET_PORT

if [ $? -eq 0 ]; then
  echo "ğŸ”€ ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆå®Ÿè¡Œ"
  switch_traffic $TARGET_ENV
  echo "âœ… Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†"
else
  echo "âŒ ç…™ãƒ†ã‚¹ãƒˆå¤±æ•— - ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"
  rollback_deployment
fi
```

### 3. æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤

#### æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
```bash
#!/bin/bash
# scripts/gradual-rollout.sh

echo "ğŸ¯ æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆé–‹å§‹"

rollout_stages=(
  "5:5åˆ†é–“"      # 5%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
  "25:15åˆ†é–“"    # 25%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
  "50:30åˆ†é–“"    # 50%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
  "100:å®Œå…¨ç§»è¡Œ" # 100%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯
)

for stage_info in "${rollout_stages[@]}"; do
  IFS=':' read -r percentage duration <<< "$stage_info"

  echo "ğŸ“Š $percentage% ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æŒ¯ã‚Šåˆ†ã‘é–‹å§‹ ($duration)"

  # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼è¨­å®šæ›´æ–°
  update_load_balancer_weight $percentage

  # ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª
  monitor_deployment $percentage "$duration"

  if [ $? -ne 0 ]; then
    echo "âŒ ç•°å¸¸æ¤œå‡º - ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"
    emergency_rollback
    exit 1
  fi

  echo "âœ… $percentage% æ®µéšå®Œäº†"
done

echo "ğŸ‰ æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Œäº†"
```

---

## ğŸ” ç›£è¦–ãƒ»ãƒ­ã‚°ç®¡ç†

### 1. çµ±åˆãƒ­ã‚°åé›†

#### Fluentdè¨­å®š
```ruby
# config/fluentd/workflow-microservices.conf
<source>
  @type tail
  path /var/log/workflow/*.log
  pos_file /var/log/fluentd/workflow.log.pos
  tag workflow.*
  format json
  time_key timestamp
</source>

<filter workflow.**>
  @type record_transformer
  <record>
    service_name ${tag_parts[1]}
    environment #{ENV['NODE_ENV']}
    server_name #{ENV['HOSTNAME']}
  </record>
</filter>

<match workflow.**>
  @type elasticsearch
  host elasticsearch.internal
  port 9200
  index_name workflow-logs
  type_name microservice
</match>
```

#### ãƒ­ã‚°æ§‹é€ çµ±ä¸€
```typescript
// utils/logger.ts - çµ±ä¸€ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
interface LogEntry {
  timestamp: string;
  level: LogLevel;
  service: string;
  traceId: string;
  message: string;
  metadata?: {
    userId?: number;
    endpoint?: string;
    duration?: number;
    errorCode?: string;
  };
}

class MicroserviceLogger {
  constructor(private serviceName: string) {}

  info(message: string, metadata?: any) {
    this.log('INFO', message, metadata);
  }

  error(message: string, error?: Error, metadata?: any) {
    this.log('ERROR', message, {
      ...metadata,
      error: error?.message,
      stack: error?.stack
    });
  }

  private log(level: LogLevel, message: string, metadata?: any) {
    const entry: LogEntry = {
      timestamp: new Date().toISOString(),
      level,
      service: this.serviceName,
      traceId: this.getTraceId(),
      message,
      metadata
    };

    console.log(JSON.stringify(entry));
  }
}
```

### 2. åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°

#### Jaegerçµ±åˆ
```typescript
// utils/tracing.ts
import { initTracer } from 'jaeger-client';

const tracer = initTracer({
  serviceName: process.env.SERVICE_NAME || 'workflow-service',
  sampler: {
    type: 'const',
    param: 1, // å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒˆãƒ¬ãƒ¼ã‚¹
  },
  reporter: {
    logSpans: true,
    agentHost: 'jaeger-agent',
    agentPort: 6832,
  },
});

export class TracingMiddleware {
  middleware() {
    return (req: Request, res: Response, next: NextFunction) => {
      const span = tracer.startSpan(`${req.method} ${req.path}`);

      span.setTag('http.method', req.method);
      span.setTag('http.url', req.url);
      span.setTag('service.name', process.env.SERVICE_NAME);

      req.span = span;

      res.on('finish', () => {
        span.setTag('http.status_code', res.statusCode);
        span.finish();
      });

      next();
    };
  }
}
```

### 3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

#### Prometheusçµ±åˆ
```typescript
// utils/metrics.ts
import prometheus from 'prom-client';

class WorkflowMetrics {
  private httpRequestDuration = new prometheus.Histogram({
    name: 'http_request_duration_seconds',
    help: 'Duration of HTTP requests in seconds',
    labelNames: ['method', 'route', 'status_code', 'service'],
    buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
  });

  private httpRequestsTotal = new prometheus.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code', 'service']
  });

  private activeConnections = new prometheus.Gauge({
    name: 'active_connections',
    help: 'Number of active connections',
    labelNames: ['service']
  });

  middleware() {
    return (req: Request, res: Response, next: NextFunction) => {
      const start = Date.now();

      res.on('finish', () => {
        const duration = (Date.now() - start) / 1000;

        this.httpRequestDuration
          .labels(req.method, req.route?.path || req.path, res.statusCode.toString(), process.env.SERVICE_NAME)
          .observe(duration);

        this.httpRequestsTotal
          .labels(req.method, req.route?.path || req.path, res.statusCode.toString(), process.env.SERVICE_NAME)
          .inc();
      });

      next();
    };
  }
}
```

---

## ğŸš¨ éšœå®³å¯¾å¿œãƒ•ãƒ­ãƒ¼

### 1. éšœå®³æ¤œå‡ºãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ

#### è‡ªå‹•éšœå®³æ¤œå‡º
```typescript
// monitoring/health-checker.ts
class HealthChecker {
  private services = [
    { name: 'workflow-types', port: 8001 },
    { name: 'workflow-requests', port: 8002 },
    // ... å…¨9ã‚µãƒ¼ãƒ“ã‚¹
  ];

  async runHealthChecks() {
    const results = [];

    for (const service of this.services) {
      const result = await this.checkService(service);
      results.push(result);

      if (!result.healthy) {
        await this.triggerAlert(service, result);
      }
    }

    return results;
  }

  private async checkService(service: ServiceConfig) {
    try {
      const response = await axios.get(`http://localhost:${service.port}/health`, {
        timeout: 5000
      });

      return {
        service: service.name,
        healthy: response.status === 200,
        responseTime: response.headers['x-response-time'],
        lastCheck: new Date()
      };
    } catch (error) {
      return {
        service: service.name,
        healthy: false,
        error: error.message,
        lastCheck: new Date()
      };
    }
  }
}
```

### 2. éšœå®³ãƒ¬ãƒ™ãƒ«åˆ†é¡

#### éšœå®³ãƒ¬ãƒ™ãƒ«å®šç¾©
```json
{
  "incident_levels": {
    "P1_CRITICAL": {
      "description": "å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒ»ãƒ‡ãƒ¼ã‚¿ç ´æ",
      "response_time": "5åˆ†ä»¥å†…",
      "escalation": "å³åº§ã«è²¬ä»»è€…é€£çµ¡",
      "actions": ["ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", "ãƒ‡ãƒ¼ã‚¿å¾©æ—§", "é¡§å®¢é€šçŸ¥"]
    },
    "P2_HIGH": {
      "description": "ä¸»è¦æ©Ÿèƒ½åœæ­¢ãƒ»æ€§èƒ½å¤§å¹…åŠ£åŒ–",
      "response_time": "15åˆ†ä»¥å†…",
      "escalation": "ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼çµŒç”±",
      "actions": ["ä»£æ›¿æ‰‹æ®µé©ç”¨", "åŸå› èª¿æŸ»", "ä¿®æ­£é©ç”¨"]
    },
    "P3_MEDIUM": {
      "description": "ä¸€éƒ¨æ©Ÿèƒ½åœæ­¢ãƒ»è»½å¾®ãªæ€§èƒ½åŠ£åŒ–",
      "response_time": "1æ™‚é–“ä»¥å†…",
      "escalation": "é€šå¸¸ãƒ•ãƒ­ãƒ¼",
      "actions": ["ç›£è¦–å¼·åŒ–", "è¨ˆç”»çš„ä¿®æ­£"]
    }
  }
}
```

### 3. ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †

#### è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
```bash
#!/bin/bash
# scripts/emergency-rollback.sh

echo "ğŸš¨ ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯é–‹å§‹"

# ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç‰¹å®š
CURRENT_VERSION=$(get_current_version)
PREVIOUS_VERSION=$(get_previous_stable_version)

echo "ğŸ“¦ $CURRENT_VERSION â†’ $PREVIOUS_VERSION ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"

# 1. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åœæ­¢
echo "ğŸ›‘ æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åœæ­¢"
stop_traffic_to_version $CURRENT_VERSION

# 2. å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "ğŸ” å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
if ! health_check_version $PREVIOUS_VERSION; then
  echo "âŒ å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚ç•°å¸¸ - æ‰‹å‹•å¯¾å¿œãŒå¿…è¦"
  notify_emergency_team
  exit 1
fi

# 3. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆ
echo "ğŸ”€ å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆ"
switch_traffic_to_version $PREVIOUS_VERSION

# 4. å‹•ä½œç¢ºèª
echo "âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª"
run_smoke_tests

# 5. é€šçŸ¥ãƒ»ãƒ­ã‚°
echo "ğŸ“¢ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†é€šçŸ¥"
notify_rollback_completion $CURRENT_VERSION $PREVIOUS_VERSION

echo "âœ… ç·Šæ€¥ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†"
```

---

## ğŸ”§ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ‰‹é †

### 1. å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
```bash
#!/bin/bash
# scripts/weekly-maintenance.sh

echo "ğŸ”§ é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹"

# 1. ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
echo "ğŸ“‹ ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"
logrotate /etc/logrotate.d/workflow-microservices

# 2. ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
echo "ğŸ—‘ï¸ ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"
find /var/log/workflow -name "*.log.*" -mtime +30 -delete
find /tmp -name "workflow-*" -mtime +7 -delete

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
echo "ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–"
npm run db:optimize

# 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
echo "ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"
npm run analyze:performance

# 5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
echo "ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³"
npm audit --audit-level moderate

echo "âœ… é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†"
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
```sql
-- scripts/optimize-database.sql

-- æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
SELECT schemaname, tablename, indexname, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_tup_read = 0 AND idx_tup_fetch = 0;

-- ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæ›´æ–°
ANALYZE logs;
ANALYZE workflow_requests;
ANALYZE approval_history;

-- æ–­ç‰‡åŒ–è§£æ¶ˆ
REINDEX INDEX CONCURRENTLY logs_timestamp_idx;
REINDEX INDEX CONCURRENTLY workflow_requests_status_idx;

-- å¤ã„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
DELETE FROM logs WHERE created_at < NOW() - INTERVAL '90 days' AND level < 40;
```

### 3. æ€§èƒ½ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è¨­å®š
```yaml
# kubernetes/workflow-autoscaler.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: workflow-microservices-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: workflow-microservices
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

---

## ğŸ“ é‹ç”¨é€£çµ¡ä½“åˆ¶

### 1. ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[éšœå®³æ¤œå‡º] --> B{éšœå®³ãƒ¬ãƒ™ãƒ«åˆ¤å®š}
    B -->|P1 CRITICAL| C[å³åº§é€šçŸ¥]
    B -->|P2 HIGH| D[15åˆ†ä»¥å†…é€šçŸ¥]
    B -->|P3 MEDIUM| E[1æ™‚é–“ä»¥å†…é€šçŸ¥]

    C --> F[ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰]
    D --> G[é–‹ç™ºãƒãƒ¼ãƒ ]
    E --> H[æ‹…å½“è€…]

    F --> I[ç·Šæ€¥å¯¾å¿œé–‹å§‹]
    G --> J[å„ªå…ˆå¯¾å¿œé–‹å§‹]
    H --> K[é€šå¸¸å¯¾å¿œé–‹å§‹]
```

### 2. é€£çµ¡å…ˆãƒªã‚¹ãƒˆ

#### ç·Šæ€¥é€£çµ¡å…ˆ
```json
{
  "emergency_contacts": {
    "tech_lead": {
      "name": "ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰",
      "phone": "+81-90-XXXX-XXXX",
      "email": "tech-lead@company.com",
      "slack": "@tech-lead",
      "availability": "24/7"
    },
    "devops_engineer": {
      "name": "DevOpsã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
      "phone": "+81-90-XXXX-XXXX",
      "email": "devops@company.com",
      "slack": "@devops",
      "availability": "æ¥­å‹™æ™‚é–“"
    },
    "database_admin": {
      "name": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†è€…",
      "phone": "+81-90-XXXX-XXXX",
      "email": "dba@company.com",
      "slack": "@dba",
      "availability": "ã‚ªãƒ³ã‚³ãƒ¼ãƒ«"
    }
  }
}
```

---

## ğŸ“Š é‹ç”¨KPIãƒ»SLA

### 1. ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ç›®æ¨™

```json
{
  "sla_targets": {
    "availability": {
      "target": "99.9%",
      "measurement": "monthly",
      "downtime_allowance": "43.8 minutes/month"
    },
    "response_time": {
      "target": "< 100ms",
      "percentile": "95th",
      "measurement": "API endpoints"
    },
    "error_rate": {
      "target": "< 0.1%",
      "measurement": "total requests",
      "exclusions": ["client_errors"]
    },
    "deployment_frequency": {
      "target": "daily",
      "success_rate": "> 95%"
    }
  }
}
```

### 2. é‹ç”¨æŒ‡æ¨™ç›£è¦–

#### ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
```typescript
// monitoring/dashboard-config.ts
export const operationalDashboard = {
  name: 'Workflow Microservices Operations',
  panels: [
    {
      title: 'Service Availability',
      type: 'stat',
      targets: [
        'avg_over_time(up{job="workflow-microservices"}[5m]) * 100'
      ],
      thresholds: [
        { value: 99.9, color: 'green' },
        { value: 99.0, color: 'yellow' },
        { value: 95.0, color: 'red' }
      ]
    },
    {
      title: 'Response Time Distribution',
      type: 'histogram',
      targets: [
        'histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))',
        'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))',
        'histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))'
      ]
    },
    {
      title: 'Error Rate',
      type: 'graph',
      targets: [
        'rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100'
      ]
    }
  ]
};
```

---

## ğŸ› ï¸ é‹ç”¨ãƒ„ãƒ¼ãƒ«ãƒ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### 1. é‹ç”¨ã‚³ãƒãƒ³ãƒ‰é›†

```bash
# å…¨ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
./scripts/check-all-services.sh

# ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
./scripts/restart-service.sh workflow-types

# ãƒ­ã‚°ä¸€æ‹¬ç¢ºèª
./scripts/tail-all-logs.sh

# æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
./scripts/generate-performance-report.sh

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
./scripts/check-database-health.sh

# ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰
./scripts/enable-maintenance-mode.sh
```

### 2. è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### è‡ªå‹•å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# scripts/auto-recovery.sh

# ã‚µãƒ¼ãƒ“ã‚¹æ­»æ´»ç›£è¦–ãƒ»è‡ªå‹•å¾©æ—§
monitor_and_recover() {
  while true; do
    for service in "${SERVICES[@]}"; do
      if ! health_check_service $service; then
        echo "âš ï¸ $service ç•°å¸¸æ¤œå‡º - è‡ªå‹•å¾©æ—§è©¦è¡Œ"

        # 3å›ã¾ã§å†èµ·å‹•è©¦è¡Œ
        for attempt in {1..3}; do
          restart_service $service
          sleep 10

          if health_check_service $service; then
            echo "âœ… $service å¾©æ—§å®Œäº†"
            break
          fi

          if [ $attempt -eq 3 ]; then
            echo "âŒ $service è‡ªå‹•å¾©æ—§å¤±æ•— - ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
            escalate_incident $service
          fi
        done
      fi
    done

    sleep 30
  done
}
```

---

*ä½œæˆæ—¥: 2025-09-28*
*é‹ç”¨é–‹å§‹: Phase 5å®Œäº†æ™‚*
*è²¬ä»»è€…: DevOpsãƒ»SREãƒãƒ¼ãƒ *